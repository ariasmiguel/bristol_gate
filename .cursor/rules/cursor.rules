[metadata]
project_name = "R to Python Data Refactor"
description = "Refactor R scripts to Python using Pandas or Polars, and create functions to pull data from various financial and economic data sources."

[goals]
primary_goal = "Rewrite R scripts into Python using idiomatic and efficient Pandas or Polars code."
secondary_goal = "Create robust, modular data ingestion functions from APIs (FRED, Yahoo Finance, EIA, OCC) and web sources (BKR, USDA, S&P500 Index, FINRA)."

[rules.style]
prefer_pandas = true
allow_polars = true
prefer_comments = true
docstrings_required = true
follow_pep8 = true

[rules.data_sources.fred]
tool = "fredapi"
api_key_env_var = "FRED_API_KEY"
expected_function = "get_fred_series"
notes = "Pull data using FRED API; return pandas DataFrame with date as index."

[rules.data_sources.yahoo]
tool = "yfinance"
expected_function = "download"
notes = "Use yfinance for financial symbols like ^GSPC, CL=F, etc."

[rules.data_sources.eia]
tool = "requests"
custom_package = "eia2 (if replicating R logic exactly)"
notes = "Use requests or Python wrapper to access EIA API. Return time-series as DataFrame."

[rules.data_sources.bkr]
tool = "webscraping"
method = "pandas.read_excel or BeautifulSoup"
notes = "Handle Excel files or scrape from HTML tables. Store locally in 'data/raw/'."

[rules.data_sources.usda]
tool = "webscraping"
method = "requests + BeautifulSoup or pandas.read_excel"
notes = "Clean column names, standardize formats."

[rules.data_sources.silverblatt]
tool = "webscraping"
format = "PDF, Excel, HTML"
notes = "Extract from PDFs with tabula-py or pdfplumber; fallback to manual if needed."

[rules.data_sources.finra]
tool = "webscraping"
format = "Excel or HTML"
notes = "Target weekly TRACE or volume data. Normalize to DataFrame."

[rules.data_sources.occ]
tool = "requests"
notes = "Use official OCC API endpoints; parse JSON responses."

[rules.error_handling]
log_level = "INFO"
log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
error_handling_strategy = "retry_on_failure"
max_retries = 3

[rules.data_validation]
validate_schema = true
handle_missing_values = "impute_or_drop"
standardize_date_format = "YYYY-MM-DD"

[rules.performance]
use_multiprocessing = true
chunk_size = 1000

[rules.security]
api_key_storage = "environment_variables"
encrypt_sensitive_data = true

[rules.testing]
unit_tests_required = true
integration_tests_required = true

[rules.documentation]
update_readme_on_change = true
maintain_changelog = true

[output]
preferred_format = "modular Python scripts"
organize_by = "source"
save_path = "src/data_sources/"